{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1736954838829,
     "user": {
      "displayName": "MICAELA CASTIGNETTI",
      "userId": "10426802351975039371"
     },
     "user_tz": -60
    },
    "id": "lkMFS2Zj4qMB",
    "outputId": "136cc923-968a-4bac-89d4-5990efa21980"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\Python\\personalized-information-retrieval\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, ndcg_score, precision_recall_fscore_support\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1108,
     "status": "ok",
     "timestamp": 1736954841558,
     "user": {
      "displayName": "MICAELA CASTIGNETTI",
      "userId": "10426802351975039371"
     },
     "user_tz": -60
    },
    "id": "-n7STzaW4r4V",
    "outputId": "9b9fd849-5886-4a6b-b334-ef6a3c255df4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1736954841558,
     "user": {
      "displayName": "MICAELA CASTIGNETTI",
      "userId": "10426802351975039371"
     },
     "user_tz": -60
    },
    "id": "R9weKtiz4tJY"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_path = \"answer_retrieval\"\n",
    "subset_answers_path = os.path.join(data_path, \"subset_answers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "executionInfo": {
     "elapsed": 8222,
     "status": "ok",
     "timestamp": 1736954849773,
     "user": {
      "displayName": "MICAELA CASTIGNETTI",
      "userId": "10426802351975039371"
     },
     "user_tz": -60
    },
    "id": "rC7JoWS34uaT",
    "outputId": "5e350e94-16b6-4a21-ea36-a65387fb3777"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>score</th>\n",
       "      <th>views</th>\n",
       "      <th>favorite</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_questions</th>\n",
       "      <th>user_answers</th>\n",
       "      <th>tags</th>\n",
       "      <th>rel_ids</th>\n",
       "      <th>rel_scores</th>\n",
       "      <th>rel_timestamps</th>\n",
       "      <th>best_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>What are CNRS research units and how are they ...</td>\n",
       "      <td>What are CNRS research units and how are they ...</td>\n",
       "      <td>2017-12-11 16:30:20</td>\n",
       "      <td>14</td>\n",
       "      <td>2484</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1106095</td>\n",
       "      <td>[workplace_40845, workplace_40899, workplace_9...</td>\n",
       "      <td>[travel_45926, travel_46391, travel_47403, tra...</td>\n",
       "      <td>[funding, france]</td>\n",
       "      <td>[academia_100217]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1512814966, 1513014615, 1513020822]</td>\n",
       "      <td>academia_100217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academia_100456</td>\n",
       "      <td>Is there a free (as in freedom) alternative to...</td>\n",
       "      <td>Is there a free (as in freedom) alternative to...</td>\n",
       "      <td>2017-12-13 19:02:32</td>\n",
       "      <td>13</td>\n",
       "      <td>1117</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1106095</td>\n",
       "      <td>[workplace_40845, workplace_40899, workplace_9...</td>\n",
       "      <td>[travel_45926, travel_46391, travel_47403, tra...</td>\n",
       "      <td>[peer-review, open-access]</td>\n",
       "      <td>[academia_100462]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1513205016, 1536615064, 1553005541, 1615097827]</td>\n",
       "      <td>academia_100462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academia_103390</td>\n",
       "      <td>Search for StackExchange citations with Google...</td>\n",
       "      <td>Search for StackExchange citations with Google...</td>\n",
       "      <td>2018-02-06 16:40:59</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1532620</td>\n",
       "      <td>[writers_27613, writers_29562, sound_42166, so...</td>\n",
       "      <td>[skeptics_39944, philosophy_3098, philosophy_9...</td>\n",
       "      <td>[citations, google-scholar]</td>\n",
       "      <td>[academia_103391]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1517936080]</td>\n",
       "      <td>academia_103391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academia_10481</td>\n",
       "      <td>Reproducible research and corporate identity M...</td>\n",
       "      <td>Reproducible research and corporate identity</td>\n",
       "      <td>2013-06-06 09:11:05</td>\n",
       "      <td>18</td>\n",
       "      <td>372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1106095</td>\n",
       "      <td>[academia_1698, academia_1772, academia_1911, ...</td>\n",
       "      <td>[academia_1699, academia_1700, academia_1701, ...</td>\n",
       "      <td>[copyright, creative-commons]</td>\n",
       "      <td>[academia_10499]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1370596608, 1370601095]</td>\n",
       "      <td>academia_10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academia_10649</td>\n",
       "      <td>Advantages of second marking In the UK a porti...</td>\n",
       "      <td>Advantages of second marking</td>\n",
       "      <td>2013-06-17 12:24:37</td>\n",
       "      <td>6</td>\n",
       "      <td>1235</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1106095</td>\n",
       "      <td>[academia_1698, academia_1772, academia_1911, ...</td>\n",
       "      <td>[academia_1699, academia_1700, academia_1701, ...</td>\n",
       "      <td>[assessment]</td>\n",
       "      <td>[academia_10650]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1371477146, 1371477156, 1371552185]</td>\n",
       "      <td>academia_10650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  \\\n",
       "0  academia_100305  What are CNRS research units and how are they ...   \n",
       "1  academia_100456  Is there a free (as in freedom) alternative to...   \n",
       "2  academia_103390  Search for StackExchange citations with Google...   \n",
       "3   academia_10481  Reproducible research and corporate identity M...   \n",
       "4   academia_10649  Advantages of second marking In the UK a porti...   \n",
       "\n",
       "                                               title           timestamp  \\\n",
       "0  What are CNRS research units and how are they ... 2017-12-11 16:30:20   \n",
       "1  Is there a free (as in freedom) alternative to... 2017-12-13 19:02:32   \n",
       "2  Search for StackExchange citations with Google... 2018-02-06 16:40:59   \n",
       "3       Reproducible research and corporate identity 2013-06-06 09:11:05   \n",
       "4                       Advantages of second marking 2013-06-17 12:24:37   \n",
       "\n",
       "   score  views  favorite  user_id  \\\n",
       "0     14   2484       2.0  1106095   \n",
       "1     13   1117       2.0  1106095   \n",
       "2      2    157       1.0  1532620   \n",
       "3     18    372       1.0  1106095   \n",
       "4      6   1235       2.0  1106095   \n",
       "\n",
       "                                      user_questions  \\\n",
       "0  [workplace_40845, workplace_40899, workplace_9...   \n",
       "1  [workplace_40845, workplace_40899, workplace_9...   \n",
       "2  [writers_27613, writers_29562, sound_42166, so...   \n",
       "3  [academia_1698, academia_1772, academia_1911, ...   \n",
       "4  [academia_1698, academia_1772, academia_1911, ...   \n",
       "\n",
       "                                        user_answers  \\\n",
       "0  [travel_45926, travel_46391, travel_47403, tra...   \n",
       "1  [travel_45926, travel_46391, travel_47403, tra...   \n",
       "2  [skeptics_39944, philosophy_3098, philosophy_9...   \n",
       "3  [academia_1699, academia_1700, academia_1701, ...   \n",
       "4  [academia_1699, academia_1700, academia_1701, ...   \n",
       "\n",
       "                            tags            rel_ids rel_scores  \\\n",
       "0              [funding, france]  [academia_100217]        [1]   \n",
       "1     [peer-review, open-access]  [academia_100462]        [1]   \n",
       "2    [citations, google-scholar]  [academia_103391]        [1]   \n",
       "3  [copyright, creative-commons]   [academia_10499]        [1]   \n",
       "4                   [assessment]   [academia_10650]        [1]   \n",
       "\n",
       "                                     rel_timestamps      best_answer  \n",
       "0              [1512814966, 1513014615, 1513020822]  academia_100217  \n",
       "1  [1513205016, 1536615064, 1553005541, 1615097827]  academia_100462  \n",
       "2                                      [1517936080]  academia_103391  \n",
       "3                          [1370596608, 1370601095]   academia_10499  \n",
       "4              [1371477146, 1371477156, 1371552185]   academia_10650  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 10000, Test examples: 100, Val examples: 100\n"
     ]
    }
   ],
   "source": [
    "# Function to load data from jsonl. this one makes everything into one dataframe. i changed it to a data frame, it should work better in theory\n",
    "def load_subset_data(folder):\n",
    "    file_path = os.path.join(data_path, folder, \"subset_data.jsonl\")\n",
    "    return pd.read_json(file_path, lines=True)\n",
    "\n",
    "# Load data for train, test, and val\n",
    "train_data = load_subset_data(\"train\")\n",
    "test_data = load_subset_data(\"test\")\n",
    "val_data = load_subset_data(\"val\")\n",
    "display(train_data.head()) # - to print in a nice way the first rows of the matrix\n",
    "\n",
    "print(f\"Train examples: {len(train_data)}, Test examples: {len(test_data)}, Val examples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHANGE**: I modified the following block of code to avoid opening the same file twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1736954850711,
     "user": {
      "displayName": "MICAELA CASTIGNETTI",
      "userId": "10426802351975039371"
     },
     "user_tz": -60
    },
    "id": "HTgVqDq14w7o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total answers loaded: 9398\n"
     ]
    }
   ],
   "source": [
    "# Load subset_answers, this time I uploaded it as a list, cause i had trouble working with it as a dictionary\n",
    "def load_subset_answers() -> dict:\n",
    "    with open(subset_answers_path) as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def convert_subset_answers_to_list(subset_answers: dict) -> list:\n",
    "    return [(k, v) for k, v in subset_answers.items()]\n",
    "\n",
    "#also as a dictionary cause at the end we need to be able to retrieve the answers from the keys\n",
    "answers_dict: dict = load_subset_answers()\n",
    "answers_list: list = convert_subset_answers_to_list(answers_dict)\n",
    "\n",
    "print(f\"Total answers loaded: {len(answers_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1736954850711,
     "user": {
      "displayName": "MICAELA CASTIGNETTI",
      "userId": "10426802351975039371"
     },
     "user_tz": -60
    },
    "id": "2YzEUjqN4yVP",
    "outputId": "01eb3544-52bc-4779-fee2-1ab72511fed9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After what George was Georgetown University na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can someone explain why Garou made Saitama do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why did Madara want to resurrect if with the E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the ~/Applications directory for? I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to make notification but no noise when tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What are the main criteria used by the Europea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>What happened to most of Five Star Movement (M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>How did Dumbledore know what Ron saw in the Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Do the residents of Facade talk in a language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>According to the Catholic Church, is assassina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   After what George was Georgetown University na...\n",
       "1   Can someone explain why Garou made Saitama do ...\n",
       "2   Why did Madara want to resurrect if with the E...\n",
       "3   What is the ~/Applications directory for? I wa...\n",
       "4   How to make notification but no noise when tim...\n",
       "..                                                ...\n",
       "95  What are the main criteria used by the Europea...\n",
       "96  What happened to most of Five Star Movement (M...\n",
       "97  How did Dumbledore know what Ron saw in the Mi...\n",
       "98  Do the residents of Facade talk in a language ...\n",
       "99  According to the Catholic Church, is assassina...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Extract questions and answers from subset_data.jsonl\n",
    "def extract_questions_and_answers(data):\n",
    "    questions = data[['text']]\n",
    "    answers = data[['best_answer']]\n",
    "    return questions, answers\n",
    "\n",
    "train_questions, train_answers = extract_questions_and_answers(train_data)\n",
    "test_questions, test_answers = extract_questions_and_answers(test_data)\n",
    "val_questions, val_answers = extract_questions_and_answers(val_data)\n",
    "\n",
    "display(test_questions)\n",
    "print(type(test_questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1736954850712,
     "user": {
      "displayName": "MICAELA CASTIGNETTI",
      "userId": "10426802351975039371"
     },
     "user_tz": -60
    },
    "id": "_SuIj6Fr4zbT",
    "outputId": "d55641ad-16c4-4eb3-94ed-6947eab2c27c"
   },
   "outputs": [],
   "source": [
    "\n",
    "punctuations = list(string.punctuation)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = \"\".join(char for char in text if char not in punctuations) # Removing punctuations from the text\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "for key, text in answers_dict.items():\n",
    "    answers_dict[key] = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 corpus size: 9398\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = list(answers_dict.values())\n",
    "print(f\"BM25 corpus size: {len(tokenized_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1736954852478,
     "user": {
      "displayName": "MICAELA CASTIGNETTI",
      "userId": "10426802351975039371"
     },
     "user_tz": -60
    },
    "id": "0yjo_61u_L_w"
   },
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: After what George was Georgetown University named? After what George was Georgetown University named? Or was it named that because of where it is located?\n",
      "Top retrieved answers:\n",
      "Answer ID: academia_185179, Text: ['georgetown', 'university', 'named', 'village', 'georgetown', 'close', 'georgetown', 'predates', 'creation', 'washington', 'dc', 'significant', 'margin', 'one', 'speculate', 'like', 'many', 'places', 'east', 'coast', 'united', 'states', 'founded', 'settlers', 'britain', 'named', 'sorts', 'places', 'british', 'kings', 'queens', 'localities', 'origins', 'name', 'also', 'possible', 'course', 'linked', 'wikipedia', 'article', 'states', 'thissince', 'georgetown', 'founded', 'reign', 'george', 'ii', 'great', 'britain', 'speculate', 'town', 'named', 'another', 'theory', 'town', 'named', 'founders', 'george', 'gordon', 'george', 'beall']\n",
      "Answer ID: skeptics_37836, Text: ['huff', 'post', 'article', 'repeats', 'claim', 'corrected', 'say', 'considers', 'university', 'california', 'system', 'correction', 'language', 'also', 'amended', 'indicate', 'article', 'considering', 'university', 'california', 'system', 'california', 'state', 'university', 'systemthe', 'university', 'california', 'system', 'indeed', 'opened', 'one', 'new', 'campus', 'since', '1980', 'uc', 'merced', 'started', 'working', '20032004', 'faculty', 'members', 'began', 'arrive', '2003', 'graduate', 'students', 'tow', 'began', 'setting', 'research', 'laboratories', 'programs', 'uc', 'merceds', 'ancillary', 'research', 'facility', 'former', 'castle', 'air', 'force', 'base', 'biding', 'time', 'buildings', 'ready', 'campus', 'first', 'graduate', 'courses', 'began', 'fall', '2004but', 'california', 'state', 'university', 'program', 'opened', 'another', '3', 'universities', 'timecsusm', '1989', 'governor', 'george', 'deukmejian', 'signs', 'senate', 'bill', '365', 'law', 'bill', 'officially', 'reconstitutes', 'sdsu', 'satellite', 'campus', 'california', 'state', 'university', 'san', 'marcos', '—', 'first', 'comprehensive', 'us', 'university', 'founded', 'two', 'decades', '20th', 'campus', 'csu', 'system', 'bill', 'w', 'stacy', 'named', 'university', '’', 'first', 'president', 'tasked', 'recruiting', '12', 'founding', 'faculty', 'memberscsumb', 'founded', '1994', 'former', 'site', 'fort', 'ord', 'educators', 'community', 'leaders', 'cal', 'state', 'monterey', 'bay', 'faculty', 'staff', 'build', 'legacy', 'explore', 'innovative', 'ways', 'meet', 'needs', 'new', 'generation', 'students', 'simultaneously', 'powering', 'monterey', 'county', 'economycsuci', 'established', '2002', '’', 'youngest', '23', 'campuses', 'csu', 'familyduring', 'time', '7', 'new', 'community', 'colleges', 'opened', 'californiaclovis', 'community', 'college', 'clovis', 'community', 'college', 'originally', 'opened', 'center', '2007', '80000', 'square', 'foot', 'academic', 'center', 'one', 'complexfolsom', 'lake', 'college', 'folsom', 'lake', 'college', 'established', '2004', 'fourth', 'campus', 'los', 'rios', 'community', 'college', 'districtirvine', 'valley', 'college', 'irvine', 'valley', 'college', 'established', '1985', 'irvinemoreno', 'valley', 'college', 'moreno', 'valley', 'norco', 'campuses', 'opened', 'march', '1991', 'grown', 'rapidly', 'granted', 'initial', 'accreditation', 'january', '2010norco', 'college', 'norco', 'college', 'opened', 'students', '1991santiago', 'canyon', 'college', 'santiago', 'canyon', 'college', 'scc', 'established', '1985west', 'hills', 'college', 'lemoore', 'west', 'hills', 'college', 'lemoore', 'established', '2002there', 'community', 'colleges', 'opened', '1980', 'became', 'part', 'california', 'community', 'colleges', 'system', '1980in', 'addition', 'according', 'list', 'colleges', 'universities', 'california', 'wikipedia', 'page', '37', 'private', 'institutions', 'opened', 'since', '1980', 'two', 'since', 'closed', 'one', 'unaccredited', 'original', 'claim', 'seems', 'come', 'business', 'insider', 'appears', 'without', 'correction', 'clarification', 'see', 'dated', 'jun', '13', '2012', 'dated', 'apr', '12', '2012']\n",
      "Answer ID: academia_16379, Text: ['one', 'side', 'effect', 'university', 'famous', 'sports', 'team', 'mentioned', 'federico', 'poloni', 'comment', 'people', 'know', 'name', 'helps', 'recruit', 'new', 'students', 'helps', 'alumni', 'impress', 'potential', 'employers', 'degree', 'somewhere', 'heard', 'know', 'boise', 'state', 'university', 'actually', 'real', 'university', 'turns', 'pretty', 'good', 'one', 'football', 'field', 'blue', 'turf', 'one', 'feature', 'american', 'colleges', 'universities', 'easy', 'forget', 'often', 'middle', 'nowhere', 'pennsylvania', 'state', 'university', 'town', 'named', 'state', 'college', 'guess', 'came', 'first', 'imagine', 'thousands', 'young', 'men', 'women', 'place', 'barely', 'town', 'saturday', 'afternoon', 'start', 'organizing', 'teams', 'play', 'sports', 'start', 'going', 'nearby', 'schools', 'play', 'teams', 'grew', 'greatly', 'since', 'old', 'days', 'idea', 'residential', 'university', 'partly', 'responsible', 'providing', 'nonacademic', 'activities', 'students', 'take', 'part', 'still', 'exists', 'real', 'force', 'smaller', 'schools', 'sports', 'scholarships', 'sports', 'teams', 'playing', 'students', 'enjoy', 'part', 'campus', 'life', 'also', 'many', 'schools', 'mission', 'statements', 'include', 'character', 'formation', 'building', 'leadership', 'skills', 'case', 'actually', 'argue', 'level', 'athletic', 'competition', 'campus', 'actually', 'part', 'core', 'mission', 'maybe', 'absolute', 'vital', 'part', 'one', 'contributes', 'mission', 'course', 'ignoring', 'large', 'part', 'money', 'corruption', 'part', 'ncaa', 'division', 'level', 'college', 'athletics', 'extraordinary', 'amount', 'bothmost', 'schools', 'except', 'd3', 'schools', 'break', 'even', 'athletic', 'programs', 'americans', 'want', 'proud', 'something', 'something', 'colleges', 'athletics', 'people', 'wouldnt', 'want', 'go', 'harvard', 'didnt', 'good', 'football', 'team', 'helps', 'bring', 'diversity', 'age', 'interests', 'grades', 'money', 'colleges']\n",
      "Answer ID: movies_116156, Text: ['neighbourhood', 'helps', 'build', 'sangwoos', 'backstory', 'adds', 'certain', 'mystery', 'initially', 'characterwere', 'shown', 'gihun', 'first', 'lives', 'poor', 'neighbourhood', 'grew', 'gihun', 'sangwoos', 'mother', 'shown', 'proud', 'life', 'achievements', 'believe', 'hes', 'one', 'got', 'poverty', 'went', 'university', 'became', 'successful', 'businessman', 'à', 'la', 'rags', 'richesaccording', 'blog', 'post', 'ssangmundong', 'hood', 'defined', 'squid', 'game', 'reply', '1988', 'squid', 'game', 'set', 'ssangmundong', 'series', 'creator', 'hwang', 'donghyuk', 'grew', 'therehwang', 'wanted', 'reflect', 'competitive', 'society', 'live', 'today', 'reflecting', '“', 'losers', '”', 'struggle', 'challenges', 'life', 'yet', 'get', 'left', 'behind', 'names', 'male', 'characters', 'fact', 'named', 'real', 'people', 'knewin', 'fact', 'hwang', '’', 'life', 'reflected', 'characters', 'raised', 'poor', 'single', 'mother', 'ssangmundong', 'like', 'gihun', 'also', 'graduate', 'prestigious', 'seoul', 'national', 'university', 'like', 'sangwoo', 'live', 'high', 'expectations', 'life', 'squid', 'game', 'living', 'life', 'gihun', 'unable', 'make', 'money', 'supported', 'financially', 'motherssangmundong', 'also', 'appears', 'another', 'south', 'korean', 'series', 'reply', '1988']\n",
      "Answer ID: islam_17206, Text: ['abul', 'qasim', 'means', 'father', 'qasim', 'prophetsaw', 'sons', 'name', 'prophet', 'sayingyou', 'named', 'muhammad', 'dont', 'named', 'abul', 'qasim', 'father', 'qasim', 'another', 'person']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3704\\2756934944.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  query_example = test_questions.iloc[0][0]\n"
     ]
    }
   ],
   "source": [
    "# BM25 retrieval function\n",
    "def bm25_retrieve(query, top_n=10):\n",
    "    tokenized_query = preprocess_text(query)\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "    top_ids = [list(answers_dict.keys())[idx] for idx in top_indices]\n",
    "    return top_ids, scores[top_indices]\n",
    "\n",
    "# Example retrieval\n",
    "query_example = test_questions.iloc[0][0]\n",
    "top_ids, top_scores = bm25_retrieve(query_example, top_n=5)\n",
    "\n",
    "print(\"Query:\", str(query_example))\n",
    "print(\"Top retrieved answers:\")\n",
    "for ans_id in top_ids:\n",
    "    print(f\"Answer ID: {ans_id}, Text: {answers_dict[ans_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(retrieved_answers, test_answer_ids):\n",
    "    precision_list, recall_list = [], []\n",
    "    for retrieved, true_id in zip(retrieved_answers, test_answer_ids):\n",
    "        relevance = [1 if ans_id == true_id else 0 for ans_id in retrieved]\n",
    "        precision = sum(relevance) / len(relevance)\n",
    "        recall = sum(relevance) / 1  # Only 1 relevant document\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "    return np.mean(precision_list), np.mean(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate BM25\n",
    "def evaluate_bm25(test_questions, test_answer_ids, top_n=10):\n",
    "    precision_list, recall_list = [], []\n",
    "    for query, true_answer_id in zip(test_questions, test_answer_ids):\n",
    "        # Retrieve top-k answers\n",
    "        top_ids, _ = bm25_retrieve(query, top_n)\n",
    "\n",
    "        # Check if the true answer ID is in top-k\n",
    "        relevance = [1 if ans_id == true_answer_id else 0 for ans_id in top_ids]\n",
    "\n",
    "        # Precision and Recall\n",
    "        precision = sum(relevance) / len(relevance)\n",
    "        recall = sum(relevance) / 1  # Only 1 relevant document\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "    return np.mean(precision_list), np.mean(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2633, Recall: 0.7900\n"
     ]
    }
   ],
   "source": [
    "test_questions_list = list(test_questions[\"text\"])\n",
    "best_test_answer_ids_list = list(test_answers[\"best_answer\"])\n",
    "\n",
    "precision, recall = evaluate_bm25(test_questions_list, best_test_answer_ids_list, top_n=3)\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained BERT model and tokenizer\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for training\n",
    "class RankingDataset(Dataset):\n",
    "    def __init__(self, queries, documents, labels):\n",
    "        self.queries = queries\n",
    "        self.documents = documents\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.queries[idx], self.documents[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation for reranking\n",
    "def prepare_rerank_data(questions, answer_texts, answer_ids, bm25_scores):\n",
    "    pairs, labels = [], []\n",
    "    for query, true_id, top_ids in zip(questions, answer_ids, bm25_scores):\n",
    "        for rank, (answer_id, score) in enumerate(top_ids):\n",
    "            pairs.append((query, answers_dict[answer_id]))\n",
    "            labels.append(1 if answer_id == true_id else 0)\n",
    "    return pairs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25_scores_train = []\n",
    "\n",
    "# for query in train_questions[\"text\"]:\n",
    "#     # Tokenize the query\n",
    "#     tokenized_query = preprocess_text(query)\n",
    "\n",
    "#     # Get BM25 scores for all answers\n",
    "#     scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "#     # Retrieve the top-N results\n",
    "#     top_n = 10  # Adjust as needed\n",
    "#     top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "#     top_answers = [(list(answers_dict.keys())[idx], scores[idx]) for idx in top_indices]\n",
    "\n",
    "#     bm25_scores_train.append(top_answers)\n",
    "\n",
    "# Since it takes time to compute the bm25 scores everytime for each training data, I computed it once and in a pickle file that I sent to you\n",
    "with open(\"bm25_scores_train.pkl\", \"rb\") as file:\n",
    "    bm25_scores_train = pickle.load(file)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and val data\n",
    "bm25_scores_train = bm25_scores_train  # Use BM25 results from part 1\n",
    "pairs_train, labels_train = prepare_rerank_data(\n",
    "    train_data['text'], answers_list, train_data['best_answer'], bm25_scores_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize pairs\n",
    "def collate_fn(batch):\n",
    "    queries, documents, labels = zip(*batch)\n",
    "    inputs = tokenizer(list(queries), list(documents), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RankingDataset(*zip(*pairs_train), labels_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\Python\\personalized-information-retrieval\\.venv\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune BERT\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs, labels = batch\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs).logits.squeeze(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, MAP, and nDCG Evaluation\n",
    "def evaluate_rerank_model(model, questions, true_answers, bm25_scores):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    for query, true_id, top_ids in zip(questions, true_answers, bm25_scores):\n",
    "        pairs = [(query, answers_dict[answer_id]) for answer_id, _ in top_ids]\n",
    "        inputs = tokenizer(\n",
    "            [p[0] for p in pairs], [p[1] for p in pairs],\n",
    "            padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = model(**inputs).logits.squeeze(-1).cpu().numpy()\n",
    "\n",
    "        all_preds.append(scores)\n",
    "        all_labels.append([1 if answer_id == true_id else 0 for answer_id, _ in top_ids])\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        [l for labels in all_labels for l in labels],\n",
    "        [int(p > 0) for preds in all_preds for p in preds],\n",
    "        average=\"binary\"\n",
    "    )\n",
    "    map_score = sum([sum(l * p for l, p in zip(labels, sorted(preds, reverse=True))) for labels, preds in zip(all_labels, all_preds)]) / len(all_labels)\n",
    "    ndcg = ndcg_score(all_labels, all_preds)\n",
    "\n",
    "    return precision, recall, map_score, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_scores_val = []\n",
    "\n",
    "for query in val_questions[\"text\"]:\n",
    "    # Tokenize the query\n",
    "    tokenized_query = preprocess_text(query)\n",
    "\n",
    "    # Get BM25 scores for all answers\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    # Retrieve the top-N results\n",
    "    top_n = 5\n",
    "    top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "    top_answers = [(list(answers_dict.keys())[idx], scores[idx]) for idx in top_indices]\n",
    "\n",
    "    bm25_scores_val.append(top_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000, Recall: 0.0000, MAP: -1.9950, nDCG: 0.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\Python\\personalized-information-retrieval\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "bm25_scores_val = bm25_scores_val  # BM25 results for validation\n",
    "precision, recall, map_score, ndcg = evaluate_rerank_model(\n",
    "    model, list(val_data['text']), list(val_data['best_answer']), bm25_scores_val\n",
    ")\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, MAP: {map_score:.4f}, nDCG: {ndcg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1TF9_hP6wA3RNnbvUscH4-gmGNECS0g9b",
     "timestamp": 1736788793483
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
